{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making experiments using motionclouds\n",
    "\n",
    "\n",
    "## making psychophysics using psychopy\n",
    "\n",
    "\n",
    "### installation (preparation 3min, cooking / downloading 10 min)\n",
    "\n",
    "* it is easy to create a simple psychophysical experiment using a combination of PsychoPy and MotionClouds. Simply download the standalone psychopy binary for your computer and try to load the example script psychopy_competing.py.\n",
    "* for this, you may:\n",
    " 1. clone / download the [MC repository](https://github.com/NeuralEnsemble/MotionClouds) on github.\n",
    " 1. download [PsychoPy](http://www.psychopy.org/installation.html)\n",
    "* then, open the psychopy_competing.py file in the editor (the so-called \"PsychoPy Coder\")\n",
    "\n",
    "<img src=\"http://motionclouds.invibe.net/files/psy1.png\">\n",
    "\n",
    "### running\n",
    "\n",
    "* Hit the run button (the green round button with a runner on it), it will then:\n",
    "* tell you about some configuration parameters (be sure to enter the correct size of your screen)\n",
    "* pre-generate data\n",
    "* run the experiment, that is present a sequence of trials consisting of :\n",
    " 1. a movie presentation,\n",
    " 1. a blank screen where the program waits for a key press: UP arrow if you saw the movie going up, DOWN if down or Q / Esc to exit\n",
    " \n",
    "### results\n",
    "\n",
    "* the results are displayed at the end showing that :\n",
    "* the movies consisted of 2 MotionClouds in opposite directions (UP and DOWN) but added with different contrasts,\n",
    "* the percept was going up or down (on the y-axis) as a function of this contrast (x-axis)\n",
    "* it seems I have a slight bias for UP movements as the contrast of equal probability seems inferior to 1/2 (a proper analysis would necessitate a fit).\n",
    "\n",
    "<img src=\"http://motionclouds.invibe.net/files/psy2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Frequently asked questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental protocol\n",
    "\n",
    "These instructions were given on VSG system but should work on similar working platforms:\n",
    "\n",
    "1. Measure your experimental settings (screen size, frame rate, resolution, viewing distance) as these values will constraint your spatial and temporal sampling frequencies.\n",
    "\n",
    "2. Calibrate your screen (gamma / luminance).\n",
    "\n",
    "3. Experimental constants (with some default values):\n",
    "\n",
    " a.  $D$ : Viewing distance distance = 570 mm\n",
    "\n",
    " b.  $S$: screen size = 390 mm\n",
    "\n",
    " c.  $dt$ : Max frame period 0,01 s\n",
    "\n",
    " d.  $\\text{VA}$ : Stimulus Width in degrees of visual angle at viewing distance $D$: 38,0958\n",
    "\n",
    " e.  $f_{d}$ : Desired spatial frequency in cycles per degree - cpd\n",
    "\n",
    " f.  $V_{drift}$: Drifting velocity in degrees per second - d/s\n",
    "\n",
    " g.  $X$, $Y$ : sampling step in degrees.\n",
    "\n",
    " h.  $F_X$, $F_Y$: spatial sampling rates in cpd\n",
    "\n",
    " i.  $T$ : Stimulus duration in seconds.\n",
    "\n",
    " j.  $\\alpha$: mean orientation of the frequency component (called $\\theta$ in the scripts)\n",
    "\n",
    " k.  $\\theta$: direction of image motion.\n",
    "\n",
    "4. Parameters for the stimulus:\n",
    "\n",
    " a.  ($N_X$, $N_Y$) : Stimuli’s frame size in pixels as generated in Fourier space.\n",
    "\n",
    " b.  ($n_X$, $n_Y$): Screen resolution = 640 x 480 px (approx 0.06 deg/px)\n",
    "\n",
    " c.  ($N_frame$): Number of movie frames as generated in Fourier space.\n",
    "\n",
    " d.  $f_pref$ : Central frequency normalized in Fourier space\n",
    "\n",
    " e.  $V_X$: left - rightward motion\n",
    "\n",
    " f.  $V_Y$: up-downward motion\n",
    "\n",
    " g.  $W_X$, $W_Y$: spatial sampling frequencies in Fourier space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I compute a visual angle?\n",
    "\n",
    "\n",
    "$$VA = 2*arctan\\left( \\frac{S}{2D} \\right)$$\n",
    "where $S$ is stimulus size on the screen (X or Y) and $D$ is the viewing distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I set the spatial sampling?\n",
    "\n",
    "$X = \\frac{\\text{VA}}{n_{x}}$ is the spatial step in the x-axis and for\n",
    "the y-axis the sampling step, Y, has the same value the x-axis.\n",
    "\n",
    "In practice, the spatial sampling step (X and/or Y) can not be larger\n",
    "than the semi-period of the finest spatial frequency ($F_X$ and or $F_Y$)\n",
    "that is represented in the image. The image will not contain those\n",
    "frequency components are higher than the Nyquist frequency along the two\n",
    "axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the unit for frequencies?\n",
    "The frequency distribution is periodic with period $F_S$. The normalized\n",
    "frequency ranges from 0.0 to 1.0, which corresponds to a real frequency\n",
    "range of 0 to the sampling frequency $F_S$.\n",
    "\n",
    "The normalized frequency also wraps around 1.0 so a normalized frequency\n",
    "of 1.1 is equivalent to 0.1.\n",
    "\n",
    "When the actual frequency, $f_t$, has units of [Hz\n",
    "](http://en.wikipedia.org%2Fwiki%2FHertz),\n",
    "for example, the normalized frequencies, also denoted by $f_t$, have\n",
    "units of **cycles per sample**, and the periodicity of the normalized\n",
    "distribution is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the maximal frequency ?\n",
    "\n",
    "If a sampled signal is real-valued the periodicity of the frequency\n",
    "distribution is still $F_S$. But due to symmetry, it is completely\n",
    "defined by the content within a span of just $F_S/2$ (Nyquist frequency). \n",
    "Accordingly, some applications use that as the normalization reference\n",
    "(and the resulting units are *half-cycles per sample*).\n",
    "\n",
    "Normalization produces a distribution that is independent of the\n",
    "sample-rate, and thus one plot is sufficient for all possible\n",
    "sample-rates.\n",
    "\n",
    "```python\n",
    "fx, fy, ft = np.mgrid[(-N\\_X//2):((N\\_X-1)//2 + 1),\n",
    "(-N\\_Y//2):((N\\_Y-1)//2 + 1),(-N\\_frame//2):((N\\_frame-1)//2 + 1)]\n",
    "\n",
    "fx, fy, ft = fx\\*1./N\\_X, fy\\*1./N\\_Y, ft\\*1./N\\_frame\n",
    "```\n",
    "\n",
    "The range is always $(-0.5, 0.5)$ which corresponds to the maximum\n",
    "frequency we can represent.\n",
    "\n",
    "\n",
    "**Example:** N\\_X = N\\_Y = 512 and N\\_frames = 128 then,\n",
    "\n",
    "Nyquist limit is $2^{- 1}W\\ cyc/width$, W is the width of the stimulus.\n",
    "\n",
    "The highest frequency band considered will be centered at\n",
    "$2^{- 2}W\\ cyc/width$\n",
    "\n",
    "The blobs change spatial frequency in octave steps, the scale-k band\n",
    "will have a spatial frequency pass band centered at:\n",
    "$2^{- (k + 2)}W\\ cyc/width$\n",
    "\n",
    "easy: it's just a design choice, we could have used B\\_tf, but defining\n",
    "B\\_sf then slicing in the envelope with a B\\_V envelope was more\n",
    "intuitive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convention used in DFT**\n",
    "--------------------------\n",
    "\n",
    "From numpy.fft.ifftn(*a*, *s=None*,\n",
    "*axes=None*)[*¶*](http://www.google.com/url?q=http%3A%2F%2Fdocs.scipy.org%2Fdoc%2Fnumpy%2Freference%2Fgenerated%2Fnumpy.fft.ifftn.html%23numpy.fft.ifftn&sa=D&sntz=1&usg=AFQjCNFgC0rRFzILtS80lxG_FRr_PhAcbA)\n",
    "\n",
    "*From*\n",
    "[**http://docs.scipy.org/doc/numpy/reference/routines.fft.html:**](http://www.google.com/url?q=http%3A%2F%2Fdocs.scipy.org%2Fdoc%2Fnumpy%2Freference%2Froutines.fft.html%3A&sa=D&sntz=1&usg=AFQjCNEEnlwd7DPHe7Z-T4PYye18AC_nNg)\n",
    "\n",
    "The values in the result follow so-called “standard” order: If A =\n",
    "fft(a,n), then A[0] contains the zero-frequency term (the mean of the\n",
    "signal), which is always purely real for real inputs. **Then A[1:n/2]\n",
    "contains the positive-frequency terms, and A[n/2+1:] contains the\n",
    "negative-frequency terms,** in order of decreasingly negative frequency.\n",
    "\n",
    "For an even number of input points, A[n/2] represents both positive and\n",
    "negative Nyquist frequency (+/-0.5), and is also purely real for real\n",
    "input.\n",
    "\n",
    "For an odd number of input points, A[(n-1)/2] contains the largest\n",
    "positive frequency, while A[(n+1)/2] contains the largest negative\n",
    "frequency. The routine np.fft.fftfreq(A) returns an array giving the\n",
    "frequencies of corresponding elements in the output.\n",
    "\n",
    "The routine np.fft.fftshift(A) shifts transforms and their frequencies\n",
    "to put the zero-frequency components in the middle, and\n",
    "np.fft.ifftshift(A) undoes that shift. (...)\n",
    "\n",
    "When the input is purely real, its transform is Hermitian, i.e., the\n",
    "component at frequency ![](media/image09.png) is the complex conjugate\n",
    "of the component at frequency ![](media/image08.png), **which means that\n",
    "for real inputs there is no information in the negative frequency\n",
    "components that is not already available from the positive frequency\n",
    "components.** The family of *rfft* functions is designed to operate on\n",
    "real inputs, and exploits this symmetry by computing only the positive\n",
    "frequency components, **up to and including the Nyquist frequency**.\n",
    "Thus, n input points produce n/2+1 complex output points. The inverses\n",
    "of this family assumes the same symmetry of its input, and for an output\n",
    "of n points uses n/2+1 input points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theoretical background: Nyquist–Shannon sampling theorem**\n",
    "------------------------------------------------------------\n",
    "\n",
    "Our function is band limited to [${- F}_{B},F_{B}{}_{}$] where B stands\n",
    "for bandwidth.\n",
    "\n",
    "The [*Nyquist sampling\n",
    "theorem*](http://www.google.com/url?q=http%3A%2F%2Fen.wikipedia.org%2Fwiki%2FNyquist%25E2%2580%2593Shannon_sampling_theorem&sa=D&sntz=1&usg=AFQjCNEnip7g8qfBszTYOu0zMuhMkYZZFQ)\n",
    "provides a prescription for the nominal sampling interval required to\n",
    "avoid aliasing and to perfectly reconstruct the signal:\n",
    "\n",
    "*The sampling frequency should be at least twice the highest frequency\n",
    "contained in the signal.*\n",
    "\n",
    "$F_{S} \\geq {2F}_{B}$\n",
    "\n",
    "$F_{N} = \\ \\frac{F_{S}}{2}$ is called Nyquist frequency ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why should we use polar coordinates for  frequencies?\n",
    "\n",
    "For the $f_x$ and $f_y$ axes units are cycles/px and for ft axis is\n",
    "\n",
    "**Example:** $f_x= 0,25 cpd$ (vertical grating)\n",
    "\n",
    "$f_{\\text{s\\ }} =$\\\n",
    "\n",
    "fd is the magnitude of the spatial frequency in polar coordinates. The\n",
    "direction \\\\theta is\n",
    "$$\n",
    "\\theta=\\arctan (fx/fy) \n",
    "$$\n",
    "(w.r.t cartesian coordinates) It can be seen as the\n",
    "rotation of the gaussian envelope.\n",
    "\n",
    "$f_{x_{\\text{norm}}\\ } = \\ f_{s}\\text{cos\\ }\\theta$\n",
    "\n",
    "$f_{y_{\\text{norm}}\\ } = \\ f_{s}\\text{sin\\ }\\theta$\n",
    "\n",
    "${f_{\\text{spatial}{}_{cyc/pix}} = {(f}_{\\text{pre}f_{\\text{cpd}}}*\\ VA)/N_{x}}_{}$\n",
    "\n",
    "$V_{X} = \\ \\frac{V_{\\text{drift}}*T}{N_{f}}$\n",
    "\n",
    "$ft\\ cyc/frame = fspatial\\ /Vx$\n",
    "\n",
    "It’s not a deformation, projections (marginalization I would say) of\n",
    "gaussians are still gaussians\n",
    "\n",
    "B\\_tf = B\\_sf\\*V\n",
    "\n",
    "$V_{\\max} = \\ \\frac{VA*T}{n_{f}}$\n",
    "\n",
    "Vx=(Vdrift \\* T) / VAx\n",
    "\n",
    "VAx or N\\_X for horizontal dispalcement\n",
    "\n",
    "Vmax= Width /Length = (deg/sec)\n",
    "\n",
    "Ex: vmax= 30deg/64frames\\*0,02sec/frame = 23deg/sec\n",
    "\n",
    "Vx= 16 deg/sec\n",
    "\n",
    "Vx\\_norm = 0,68\n",
    "\n",
    "f\\_t = Vx\\_norm \\* f\\_s norm (case of drifting grating, no rotation in\n",
    "x-y axes)\n",
    "\n",
    "f\\_t = 0,68 \\* 0,03152 = 0,02\n",
    "\n",
    "\n",
    "Log-Gabor filter construction process in the Fourier domain ([*Hanssen\n",
    "and Hess, 2006, Journal of Vision*](http://www.google.com/url?q=http%3A%2F%2Fwww.journalofvision.org%2Fcontent%2F6%2F5%2F5.full&sa=D&sntz=1&usg=AFQjCNGJf9VjJ-GajjU9ZkGN1Gq8OQAy9A))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## an example physiology experiment using VSDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../files/experiment_VSDI.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../files/experiment_VSDI.py\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "experiment_VSDI.py\n",
    "Experiment designed for optical imaging showing a conversion of size from Fourier \n",
    "to screen coordinates and an export to a zipped file conaining BMP files (as the\n",
    "video card has limited memory)\n",
    "\n",
    "(c) Paula Sanz Leon - INT/CNRS\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import scipy\n",
    "import MotionClouds as mc\n",
    "import numpy as np\n",
    "\n",
    "# uncomment to preview movies\n",
    "# vext, display = None, True\n",
    "\n",
    "#------------------------- Zipped grating ------------------------------- #\n",
    "\n",
    "name = 'zipped_grating'\n",
    "\n",
    "#initialize - \n",
    "fx, fy, ft = mc.get_grids(mc.N_X, mc.N_Y, mc.N_frame)\n",
    "sf_0 = 0.2\n",
    "B_sf = sf_0 / 4.\n",
    "alpha = 1.0\n",
    "V_X = 0.5\n",
    "B_V = V_X / 10.\n",
    "\n",
    "name_ = mc.figpath + name\n",
    "for seed in range(424242, 424242+8):\n",
    "    name_ = mc.figpath + name + '-seed-' + str(seed)\n",
    "    mc.figures_MC(fx, fy, ft, name_, B_V=B_V, sf_0=sf_0, B_sf=B_sf, V_X=V_X, theta=np.pi/4., alpha=alpha, seed=seed, vext='.zip')\n",
    "\n",
    "#-------------------- Narrowband vs Braodband experiment ---------------- #\n",
    "vext = '.mpg'\n",
    "#vext = '.mat'\n",
    "#vext = '.zip'\n",
    "#display = False\n",
    "\n",
    "# Initialize frequency cube\n",
    "N_X = 640.\n",
    "N_Y = 480.\n",
    "N_frame = 30. # a full period in time frames\n",
    "fx, fy, ft = mc.get_grids(N_X, N_Y, N_frame)\n",
    "\n",
    "# Experimental constants \n",
    "contrast = 0.5\n",
    "seeds = 1\n",
    "VA = 38.0958       # VSG constants for a viewing ditance 570 mm. \n",
    "framerate = 50.    # Refreshing rate in [Hz]\n",
    "T = 0.6            # Stimulus duration [s] \n",
    "f_d = 0.5         # Desired spatial frequency [cpd]\n",
    "\n",
    "# Clouds parameters      \n",
    "B_V = 0.2     # BW temporal frequency (speed plane thickness)\n",
    "B_sf = 0.15   # BW spatial frequency\n",
    "theta = 0.0   # Central orientation\n",
    "B_theta = np.pi/12 # BW orientation\n",
    "verbose = False\n",
    "alpha = 1.0\n",
    "\n",
    "# Get normalised units\n",
    "sf_0=0.1\n",
    "V_X=0.5\n",
    "\n",
    "def physicalUnits2discreteUnits(sf0_cpd, Bsf_cpd, v_dps, B_dps,pixelPitch,viewingDistance,frameRate):\n",
    "    \"\"\"%   % laptop monitor\n",
    "    %   pixelPitch      = 0.22/10; % in cm\n",
    "    %   viewingDistance = 50;\n",
    "    %   sf0_cpd         = 4 ;\n",
    "    %   Bsf_cpd         = 1 ;\n",
    "    %   v_dps           = 4 ;\n",
    "    %   B_dps           = 1 ;\n",
    "    %   frameRate       = 20 ;\n",
    "    % convert to machine units\n",
    "    \"\"\"\n",
    "    cmPerDegree    = 2*viewingDistance*tand(1/2)\n",
    "    pxPerDegree    = cmPerDegree/pixelPitch\n",
    "    sf0            = sf0_cpd/pxPerDegree\n",
    "    Bsf            = Bsf_cpd/pxPerDegree\n",
    "\n",
    "    v              = v_dps/frameRate*pxPerDegree\n",
    "    Bv             = B_dps/frameRate*pxPerDegree\n",
    "    return sf0, Bsf, v, Bv\n",
    "\n",
    "\n",
    "# take monitor parameters\n",
    "# planar display\n",
    "monitorRefresh = 60 ;\n",
    "pixelPitch     = 0.2865/10 ;% pixelsize in cm\n",
    "\n",
    "# experiments parameter\n",
    "viewingDistance = 70 ;\n",
    "\n",
    "frameRefresh   = monitorRefresh/3 ;\n",
    "stimModRate    = 1 ;\n",
    "numberOfReps   = 12 ;\n",
    "framesPerMod   = frameRefresh/stimModRate/2 ; \n",
    "\n",
    "\n",
    "# Masks\n",
    "# gaussian mask\n",
    "sigma_mask_x = 0.15\n",
    "sigma_mask_y = 0.2\n",
    "x, y, t = mc.get_grids(N_X, N_Y, N_frame)\n",
    "n_x, n_y = N_X, N_Y\n",
    "gauss = np.exp(-(((x-172./n_x)**2/(2*sigma_mask_x**2)) + (((y-108./n_y)**2)/(2*sigma_mask_y**2))))\n",
    "\n",
    "\n",
    "def tukey(n, r=0.5):\n",
    "    '''The Tukey window, also known as the tapered cosine window, can be regarded as a \n",
    "    cosine lobe of width r * N / 2 that is convolved with a rectangle window of width \n",
    "    (1 - r / 2). At r = 1 it becomes rectangular, and at r = 0 it becomes a Hann window.\n",
    "    http://www.mathworks.com/access/helpdesk/help/toolbox/signal/tukeywin.html\n",
    "    '''\n",
    "    # Special cases\n",
    "    if r <= 0:\n",
    "        return np.ones(n.shape) #rectangular window\n",
    "    elif r >= 1:\n",
    "        return np.hanning(n.shape)\n",
    "\n",
    "    # Normal case\n",
    "    x = np.linspace(0, 1, n)\n",
    "    w = np.ones(x.shape)\n",
    "\n",
    "    # first condition 0 <= x < r/2\n",
    "    first_condition = x<r/2\n",
    "    w[first_condition] = 0.5 * (1 + np.cos(2*np.pi/r * (x[first_condition] - r/2) ))\n",
    "\n",
    "    # second condition already taken care of\n",
    "\n",
    "    # third condition 1 - r / 2 <= x <= 1\n",
    "    third_condition = x>=(1 - r/2)\n",
    "    w[third_condition] = 0.5 * (1 + np.cos(2*np.pi/r * (x[third_condition] - 1 + r/2))) \n",
    "\n",
    "    return w\n",
    "\n",
    "# Tukey mask - fading effect\n",
    "tw_x = tukey(n=n_x, r=0.15)\n",
    "tw_y = tukey(n=n_y, r=0.15)\n",
    "w = np.tile(((np.outer(tw_y,tw_x))), (N_frame,1,1))\n",
    "tukey_mask = w.T\n",
    "\n",
    "\n",
    "# Get Random Clouds\n",
    "name_ = mc.figpath + name\n",
    "\n",
    "for seed in [123456 + step for step in range(seeds)]:\n",
    "    name__ = mc.figpath + name + '-seed-' + str(seed) + '-sf0-' + str(sf_0).replace('.', '_') + '-V_X-' + str(V_X).replace('.', '_')\n",
    "    # broadband \n",
    "    z = mc.envelope_gabor(fx, fy, ft, name_, B_sf=Bsf, sf_0=sf_0, theta=theta, B_V=B_V, B_theta = B_theta, alpha=alpha)\n",
    "    movie = mc.figures(z, name=None, vext=vext, seed=seed, masking=True)    \n",
    "    for label, mask in zip(['_mask', '_tukey_mask'], [gauss, tukey_mask]):\n",
    "        name_ = name__ + '-cloud-' + label\n",
    "        if anim_exist(name_): \n",
    "            movie = mc.rectif(movie*mask)\n",
    "            mc.anim_save(movie, name_, display=False, vext=vext)\n",
    "\n",
    "   # narrowband \n",
    "    z = mc.envelope(fx, fy, ft, name_, B_sf=B_sf/10., sf_0=sf_0, theta=theta, B_V=B_V, B_theta=B_theta, alpha=alpha)\n",
    "    movie = mc.figures(z, name=None, vext=vext, seed=seed, masking=True)\n",
    "    for label, mask in zip(['_mask', 'tukey_mask'], [gauss, tukey_mask]):\n",
    "        name_ = name__ + '-blob-' + label\n",
    "        if anim_exist(name_):\n",
    "            movie = mc.rectif(movie*mask)\n",
    "            mc.anim_save(movie, name_, display=False, vext=vext)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
